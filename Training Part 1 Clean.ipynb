{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\\*Remember to activate the *far_nlp* environment before starting jupyter notebook from command line and running this notebook:**\n",
    "\n",
    "**OS X, Linux:** `$ source activate far_nlp`\n",
    "\n",
    "**Windows:** `$ activate far_nlp`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Verify the right environment is enabled by checking the python path\n",
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# How Can We Represent Text for Use in Machine Learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The classic way to represent text for machine learning is with a *term frequency matrix* also sometimes referred to as a *Bag of Words representation*. In its simplest form this means counting how many times a word appears in a document, and we do this count for each document in our collection of documents (aka our corpus). \n",
    "\n",
    "In the example below our corpus is *eagle_powers* and each sentence is considered a separate document. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "format": "row",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "eagle_powers = [\"He knows where to find the eagle eggs.\",\n",
    "        \"His eagle eggs possess magical powers.\",\n",
    "        \"Summon your eagle powers.\"\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# This is a custom script to show how vectorization works easily\n",
    "from utilities import SimpleVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "scrolled": false,
    "solution": "hidden"
   },
   "outputs": [],
   "source": [
    "SimpleVectorizer(eagle_powers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Try it Out\n",
    "Make your own test corpus by creating a new variable that contains a list of sentences. How does the vectorizer handle your corpus, does it behave as expected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Make a new list variable that contains a few sentences.\n",
    "# Pass your documents into the simpleVectorizer function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Hint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "my_corpus = [\"This is a sentance.\", \"This is another sentance.\"]\n",
    "SimpleVectorizer(my_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## How does the SimpleVectorizer fall short?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Modify your previous list and try to explore what some of the limitations of the SimpleVectorizer might be. For example, how does it handle capitalization? If the goal of vectorizing is capturing the meaning (or similarity of like documents), how does it fall short? How does it perform well? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Try it Out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Try to find shortcomings of the SimpleVectorizer by modifying your document corpus.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Hint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "my_corpus = [\"He ran yesterday.\", \"Run over there!\", \"Running a meeting is hard.\", \"The river runs east.\"]\n",
    "SimpleVectorizer(my_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Discussion\n",
    "\n",
    "What did we find?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Under the Hood of the SimpleVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Before we move on and see options for creating a a term frequency matrix, let's look under the hood of our SimpleVectorizer function and see how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Run this cell to see the components of the SimpleVectorizer function\n",
    "??SimpleVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "source": [
    "The SimpleVectorizer function is using a function called CountVectorizer from sci-kit learn to build the term frequency matrix. Let's see how to use CountVectorizer on its own.\n",
    "\n",
    "To use CountVectorizer we'll have to:\n",
    "1. Import it from sci-kit learn\n",
    "2. Instantiate it\n",
    "3. And call ```fit_transform``` on a set of documents.\n",
    "\n",
    "See the sci-kit learn docs on [CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Import CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Instantiate CountVectorizer, this makes an instance of CV\n",
    "# with whatever options you specify.\n",
    "CV = CountVectorizer(lowercase=False, min_df=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fit CountVectoroizer instance on our document corpus\n",
    "# The result is a sparse matrix\n",
    "results = CV.fit_transform(eagle_powers)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Here is what the sparse representation looks like\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# To see what this looks like as a regular matrix we need to use .todense()\n",
    "results.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Import the displayTFMatrix function to view the matrix as we have been.\n",
    "# For this function, pass in the CountVectorizer instance and the documents\n",
    "# that will be vectorized.\n",
    "from utilities import DisplayTFMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "DisplayTFMatrix(CV, eagle_powers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Try it Out:\n",
    "Repeat the steps above using your own document corpus to:\n",
    "1. **Instantiate CountVectorizer:** Make a new instance of CountVectorizer, you can set it equal to *CV* or anything else that makes sense to you.\n",
    "2. **Transform your Corpus:** Call the ```fit_transform``` method on the new CountVectorizer instance and pass in your corpus. Set this to a variable to capture the resulting sparse matrix.\n",
    "3. **View Sparse Representation of the Matrix:** View the sparse version of your term frequency matrix using ```print()```.\n",
    "4. **View Dense Representation of the Matrix:** View the dense representation of your term frequency matrix by calling `.todense()` on variable containing your term frequency matrix.\n",
    "5. **View the DataFrame:** View the data frame of your term frequency matrix using ```DisplayTFMatrix(CVInstance, corpus)```. Make sure to pass in the CountVectorizer instance and your corpus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Improving on Term Frequency Matricies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Two of the main issues with Term Frequency Matrices are:\n",
    "- **Size:** They grow logarithmically to the number of documents in the corpus and get large very fast. This can lead to high computing costs, it can take a long time to vectorize all of the documents in a corpus.\n",
    "- **Noise:** Related to the first problem is that these representations of documents also contain a lot of noise. There is a lot of extra information that may not be helpful for our machine learning task. For example, is the word *the* indicative of document content? Is it useful to have a count for this word?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Stop Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Stop words are words that we want to ommit from being counted. This could be because we don't think they convey any important meaning or we may want to omit them for other reasons.\n",
    "\n",
    "We can set the stop words by passing in `stopwords=\"english\"` as a parameter in count vectorizer. We can also pass in a list of our own custom words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# See what happens when we use the list of stopwords provided \n",
    "# with sci-kit learn.\n",
    "\n",
    "CV = CountVectorizer(stop_words=\"english\", lowercase=False)\n",
    "DisplayTFMatrix(CV, eagle_powers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check out the default list of stop words from sk learn\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "ENGLISH_STOP_WORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Try it Out:\n",
    "Make a new list variable that will contain a list of custom stopwords. Use the default stopwords from sci-kit learn as the starting point for the new list. Then append your own stopwords to the new stopwords list. Use ```DisplayTFMatrix()``` to see the effects of using the new stopwords list on your custom corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Hint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# Set the defualt stopwords to a new list variable. You need\n",
    "# to change it to a list because the original list is a frozen set and will\n",
    "# not allow you to add on other words\n",
    "custom_stop_words = list(ENGLISH_STOP_WORDS)\n",
    "\n",
    "# My custom Words\n",
    "new_stop_words = [\"eagle\",\"magical\",\"powers\"]\n",
    "\n",
    "# Add my words to the default stop words\n",
    "custom_stop_words.extend(new_stop_words)\n",
    "\n",
    "# Make a TF Matrix using my custom stop words.\n",
    "CV = CountVectorizer(stop_words=custom_stop_words, lowercase=False)\n",
    "DisplayTFMatrix(CV, eagle_powers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Minimum and Maximum Limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# To see how minimum and maxim limits work, it will help to\n",
    "# have a larger corpus with even more eagle powers.\n",
    "more_eagle_powers = [\"He knows where to find the eagle eggs.\",\n",
    "                     \"Eagle eggs?\",\n",
    "                     \"His eagle eggs possess magical powers.\",\n",
    "                     \"For you to become empowered by the eagle you must climb that cliff\",\n",
    "                     \"Find the egg and drink it.\",\n",
    "                     \"Summon your eagle powers.\",\n",
    "                     \"Eagle powers, come to me! Please!\"\n",
    "                    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<img style=\"float: left;\" src=\"img/eagle_powers.gif\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# We can also get rid of the most and least frequent\n",
    "# words by setting minimum and maximum limits.\n",
    "# This can also reduce the matrix size and reduce noise.\n",
    "\n",
    "# CV = CountVectorizer(lowercase=False)\n",
    "CV = CountVectorizer(min_df=2, max_df=6, lowercase=False)\n",
    "DisplayTFMatrix(CV, more_eagle_powers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Try it Out:\n",
    "\n",
    "Use the example above to do the following:\n",
    "\n",
    "- Add a few more sentences to your document corpus. Make sure to have some words that occur frequently throughout documents in the corpus so you can see the effects of setting a maximum term frequency.\n",
    "- Vectorize your corpus with CountVectorizer using upper and lower limits to see how it affects the final matrix.\n",
    "- Also, notice that we've been seeing a lowercase option for CountVectorizer. Set `lowercase=True` to have all the letters converted to lowercase notice how this effects the outcome in the final term frequency matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## NGrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Instead of tokenizing a single word we can tokeninze several words at a time to get a better sense of meaning and nuance in the text. However, we also need to keep in mind this can greatly increase the the size of our matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# This is what our TF matrix looks like without using ngrams.\n",
    "# Or in other words using an ngram of 1, or a unigram\n",
    "# Note the size: 3 rows, 14 columns\n",
    "CV = CountVectorizer()\n",
    "DisplayTFMatrix(CV, eagle_powers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Now let's see what it looks like using an ngram range of 2-3.\n",
    "# This means we'll have only 2 and 3 word strings.\n",
    "# Notice the new size of the dataFrame\n",
    "\n",
    "CV = CountVectorizer(ngram_range=(2,3))\n",
    "DisplayTFMatrix(CV, eagle_powers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Try it Out:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Make a Term Frequency matrix using `ngram_range`. Experiment with different ranges to see how it affects the final matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Your Code Here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Hint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "CV = CountVectorizer(ngram_range=(1,3))\n",
    "DisplayTFMatrix(CV, eagle_powers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Truncated SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "As we've seen with ngrams, it is easy for a vectorized corpus to become very wide and have a large number of features/columns. Truncated SVD allows us to reduce the dimensionality of our data (the number of features/columns) while maintaining a large degree of the variance from the original data. Truncated SVD works efficiently with data in sparse form, so it works well with the output from CountVectorizer.\n",
    "\n",
    "Scikit learn reference: [TruncatedSVD](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html)\n",
    "\n",
    "More info on TFIDF and how it works:\n",
    "- [https://www.quora.com/What-is-an-intuitive-explanation-of-singular-value-decomposition-SVD/answer/Jason-Liu-21?srid=nGs9](https://www.quora.com/What-is-an-intuitive-explanation-of-singular-value-decomposition-SVD/answer/Jason-Liu-21?srid=nGs9)\n",
    "- [https://stats.stackexchange.com/questions/134282/relationship-between-svd-and-pca-how-to-use-svd-to-perform-pca](https://stats.stackexchange.com/questions/134282/relationship-between-svd-and-pca-how-to-use-svd-to-perform-pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Let's generate a wide term frequency matrix for comparison\n",
    "CV = CountVectorizer(ngram_range=(1,3))\n",
    "\n",
    "# The original matrix has 94 columns for this \n",
    "DisplayTFMatrix(CV, more_eagle_powers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Now Let's use TSVD\n",
    "\n",
    "# Vectorize the documents with CV\n",
    "CV = CountVectorizer(ngram_range=(1,3))\n",
    "cv_results = CV.fit_transform(more_eagle_powers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Like other methods we need to import TSVD before use\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Then instantiate TSVD and set parameters\n",
    "TSVD = TruncatedSVD(n_components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Fit TSVD on our term matrix, note it is not sparse\n",
    "tsvd_result = TSVD.fit_transform(cv_results)\n",
    "tsvd_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Dispaly the TSVD results\n",
    "pd.DataFrame(tsvd_result, index=more_eagle_powers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# We can see how much of the variance from the original data\n",
    "# is retained by using explained_variance_ratio_\n",
    "# With only two columns of data we're capturing 43% of the variance\n",
    "\n",
    "TSVD.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Try it Out:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "1. Make a wide term frequency matrix (use something like an `ngram_range(1,3)` or more) and set the results to a variable.\n",
    "2. Use Truncated SVD to reduce the columns of this data set to 2 columns.\n",
    "3. Display the results of the new matrix.\n",
    "4. Use `.explained_variance_ratio_` to see how much of the variance of the original data that each column captures.\n",
    "5. Adjust the `n_components` setting in Truncated SVD so that you are capturing 70%-80% of the variation of the original data. How many columns does this end up being? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Hint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# Vectorize the corpus\n",
    "CV = CountVectorizer(ngram_range=(1,5))\n",
    "cv_results = CV.fit_transform(more_eagle_powers)\n",
    "\n",
    "# Use TSVD on the Term Frequency Matrix\n",
    "TSVD = TruncatedSVD(n_components=2)\n",
    "tsvd_results = TSVD.fit_transform(cv_results)\n",
    "\n",
    "# Display the resulting reduced-feature Matrix \n",
    "display(pd.DataFrame(tsvd_result, index=more_eagle_powers))\n",
    "# Display how much variance was captured in each column\n",
    "display(TSVD.explained_variance_ratio_)\n",
    "\n",
    "\n",
    "# Adjust n_components to caputre 70% of the variance\n",
    "TSVD = TruncatedSVD(n_components=4)\n",
    "tsvd_results = TSVD.fit_transform(cv_results)\n",
    "\n",
    "# Display matrix and variance\n",
    "display(pd.DataFrame(tsvd_result, index=more_eagle_powers))\n",
    "display(TSVD.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "heading_collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Term frequency-inverse document frequency (TF-IDF) is a way of weighting words that gives the highest value to words which occur frequently in a specific document but occurs less frequently in the overall corpus.\n",
    "\n",
    "1. Highest when a term occurs many times within a small number of documents (thus lending high discriminating power to those documents);\n",
    "\n",
    "2. Lower when a term occurs fewer times in a document, or occurs in many documents (thus offering a less pronounced relevance signal);\n",
    "\n",
    "3. Lowest when a term occurs in virtually all documents.\n",
    "\n",
    "**Above taken from second resource linked to below.*\n",
    "\n",
    "Resources for learning more about TF-IDF:\n",
    "- Good introduction to the idea of TF-IDF: [http://www.tfidf.com/](http://www.tfidf.com/)\n",
    "- [Introduction to Information Retrieval: TF-idf Stanford](https://nlp.stanford.edu/IR-book/html/htmledition/tf-idf-weighting-1.html)\n",
    "- Details on Sci-kit learn's specific implementation of TF-IDF: [Tf–idf term weighting](http://scikit-learn.org/stable/modules/feature_extraction.html#tfidf-term-weighting)\n",
    "- Documentatio for using Tf-Idf in sci-kit learn: [sklearn.feature_extraction.text.TfidfVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This is the basic concept of the math behind TF-IDF. However, there are several different implementations and options that can be added to TF-IDF so you may see slightly different formulas out in the wild.\n",
    "\n",
    "$\\text{tfidf}_t = \\frac{\\text{number of times a word appears in a document}}{\\text{total number of words in a document}} \\cdot log( \\frac{\\text{total number of documents in corpus}}{\\text{number of documents in corpus where a word appears at least once}} )$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**A quick TFIDF example (taken from [tfidf.com](http://www.tfidf.com/))**\n",
    "\n",
    "Our goal is to calculate the TFIDF value for the word *cat* in the given document below:\n",
    "- Our document has a total of 100 words.\n",
    "- The word *cat* occurs 3 times in the document.\n",
    "- Our corpus has 10,000,000 documents total.\n",
    "- The word cat occurs at least once in 1,000 documents in our corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from math import log\n",
    "\n",
    "normalized_term_frequency = 3/100\n",
    "inverse_document_frequency = log(10000000/1000, 10)\n",
    "tfidf_value = normalized_term_frequency*inverse_document_frequency\n",
    "\n",
    "print(\"The normalized term frequency is: \", normalized_term_frequency)\n",
    "print(\"The inverse document frequency is: \", inverse_document_frequency)\n",
    "print(\"The TF-IDF value for the word cat in our document is: \", tfidf_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Similar to CountVectorizer we need to import TFIDF Vectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Instantiate TFIDF\n",
    "TFIDF = TfidfVectorizer()\n",
    "\n",
    "# Display TFIDF\n",
    "DisplayTFMatrix(TFIDF, eagle_powers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Look over the matrix above to get a feel for what TFIDF is doing.\n",
    "\n",
    "- What words have the highest value, and the lowest?\n",
    "- For words that occur in all documents, why are values different or the same across documents?\n",
    "\n",
    "**Some may notice that the values are not the same as if we calculated them by hand using the formula above. I'm guessing this is due to Sci-kit learn's specific way of implementing TF-IDF.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Try it Out:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Use `TfidfVectorizer()` to vectorize your corpus and then use `DisplayTFMatrix()` to display it. Examine the results and answer the same questions as above:\n",
    "- What words have the highest value, and the lowest?\n",
    "- For words that occur in all documents, why are values different or the same across documents?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Your Code Here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Hint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "TFIDF = TfidfVectorizer()\n",
    "DisplayTFMatrix(TFIDF, eagle_powers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Lemmatization is getting the base form of a word which we will then use to make our term frequency matrix. In this way, different variations of a word can be mapped to the root word. This can further reduce the size and (potentially) the noise in our Term Frequency Matrix. We'll use a NLP library called spaCy to tokenzie our text and get the lemmas. We'll pass the results from spaCy to CountVectorizer to generate our term frequency matrix.\n",
    "\n",
    "SpaCy documentation: [https://spacy.io/docs/usage/](https://spacy.io/docs/usage/)\n",
    "SpaCy can do a LOT more than what we are using it for here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# This is how we load spaCy\n",
    "import spacy              # First import the package\n",
    "nlp = spacy.load('en')    # Then load the langauge model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# let's see see how spacy works and how the lemmas compare to \n",
    "# the original text\n",
    "\n",
    "for doc in eagle_powers:\n",
    "    spacy_doc = nlp(doc)\n",
    "    for tok in spacy_doc:\n",
    "        print(\"Original:\", tok.orth_, \" | Lemma:\", tok.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#  Now let's bring together tokenization with vectorization.\n",
    "\n",
    "# Setup an empty list that will hold our tokenized (lemma) documents\n",
    "eagle_power_lemmas = []\n",
    "\n",
    "# Iterate Through each document\n",
    "for doc in more_eagle_powers: \n",
    "    \n",
    "    # Process the document with spaCy\n",
    "    spacy_doc = nlp(doc)\n",
    "    \n",
    "    # Grab the lemma for each token\n",
    "    lemmas = [token.lemma_ for token in spacy_doc] \n",
    "    \n",
    "    # Make the list of lemmas into a string\n",
    "    lemmas = \" \".join(lemmas)\n",
    "    \n",
    "    # Add the lemma string to the eagle_power_lemmas list\n",
    "    eagle_power_lemmas.append(lemmas) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Let's see what our string of lemma's looks like\n",
    "eagle_power_lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "CV = CountVectorizer()\n",
    "DisplayTFMatrix(CV, eagle_power_lemmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Try it Out:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Drawing on what we've seen above, build a function named *spacy_tokenizer* that does the following:\n",
    "- Take in a single string (document) as an argument — not a corpus or collection of docs/\n",
    "- Process the string and create a spaCy document.\n",
    "- Iterates tokens in the spaCy document and returns the lemma for each token as a list.\n",
    "- Test out the function with a single string (document)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Your Code Here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Hint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "def spacy_tokenizer(doc_as_string):\n",
    "    spacy_doc = nlp(doc_as_string)\n",
    "    tokens = [tok.lemma_ for tok in spacy_doc]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "spacy_tokenizer(\"Test some string here.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Try it Out 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now make a new instance of CountVectorizer and add the following parameter: `tokenizer=spacy_tokenizer`. Feel free to add in any of the other parameters that we've learned.\n",
    "\n",
    "Use `DisplayTFMatrix` to display the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Hint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "CV = CountVectorizer(stop_words='english', tokenizer=spacy_tokenizer)\n",
    "DisplayTFMatrix(CV, more_eagle_powers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "\n",
    "# End of Part 1"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
